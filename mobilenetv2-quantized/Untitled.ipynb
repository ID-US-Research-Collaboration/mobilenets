{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b5fd16-dbcf-48ca-86d7-71a558edaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU, TruncAvgPool2d\n",
    "from brevitas.quant import Int8WeightPerTensorFloat, Int8ActPerTensorFloat, Uint8ActPerTensorFloat, IntBias\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.bit_width import BitWidthImplType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79e405e-a867-4fbb-be8e-526e81abce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_LAYER_BIT_WIDTH = 8\n",
    "LAST_LAYER_BIT_WIDTH = 8\n",
    "INTERNAL_BIT_WIDTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155998f6-6522-43f1-ad08-ffb1a76886a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonIntWeightPerTensorQuant(Int8WeightPerTensorFloat):\n",
    "    \"\"\"\n",
    "    Common per-tensor weight quantizer with bit-width set to None so that it's forced to be\n",
    "    specified by each layer.\n",
    "    \"\"\"\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "\n",
    "\n",
    "class CommonIntWeightPerChannelQuant(CommonIntWeightPerTensorQuant):\n",
    "    \"\"\"\n",
    "    Common per-channel weight quantizer with bit-width set to None so that it's forced to be\n",
    "    specified by each layer.\n",
    "    \"\"\"\n",
    "    scaling_per_output_channel = True\n",
    "\n",
    "\n",
    "class CommonIntActQuant(Int8ActPerTensorFloat):\n",
    "    \"\"\"\n",
    "    Common signed act quantizer with bit-width set to None so that it's forced to be specified by\n",
    "    each layer.\n",
    "    \"\"\"\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP\n",
    "\n",
    "\n",
    "class CommonUintActQuant(Uint8ActPerTensorFloat):\n",
    "    \"\"\"\n",
    "    Common unsigned act quantizer with bit-width set to None so that it's forced to be specified by\n",
    "    each layer.\n",
    "    \"\"\"\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f01f4c-45d0-4975-8fe5-5d0d9c2f3e81",
   "metadata": {},
   "source": [
    "# Convolutional Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662c2f7a-bb4f-4fab-a191-5dfa20720c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        weight_bit_width,\n",
    "        act_bit_width,\n",
    "        stride=1,\n",
    "        padding=None,\n",
    "        groups=1,\n",
    "        bn_eps=1e-5,\n",
    "        activation_scaling_per_channel=False,\n",
    "        bias=False\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        self.conv = QuantConv2d(\n",
    "            in_channels = in_channels,\n",
    "            out_channels = out_channels,\n",
    "            kernel_size = kernel_size,\n",
    "            stride = stride,\n",
    "            padding = padding,\n",
    "            groups = groups,\n",
    "            bias = bias,\n",
    "            weight_bit_width = weight_bit_width, # 4 bit quantization\n",
    "            weight_quant = CommonIntWeightPerChannelQuant, # quantization per output channel\n",
    "            weight_scaling_per_output_channel=True, # each output will have its own scaling factor\n",
    "            weight_scaling_impl_type=ScalingImplType.STATS, # scaling is based on statistics of weight value --> max absolute value\n",
    "            weight_scaling_stats_op='abs_max',\n",
    "            weight_narrow_range=True, # range narrowed\n",
    "            weight_scaling_min_val=2e-16 # min value for scaling factor\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features = out_channels, eps = bn_eps)\n",
    "        self.activation = QuantReLU(\n",
    "            bit_width=act_bit_width,\n",
    "            max_val=6,\n",
    "            quant_type=QuantType.INT,\n",
    "            scaling_impl_type=ScalingImplType.PARAMETER,\n",
    "            restrict_scaling_type=RestrictValueType.LOG_FP,\n",
    "            scaling_per_channel=activation_scaling_per_channel,\n",
    "            per_channel_broadcastable_shape=(1, out_channels, 1, 1),\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b5626-8894-42c8-9bc2-d139c949dd87",
   "metadata": {},
   "source": [
    "# Inverted Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6248a-ec9b-43b6-9a06-4456f7fd1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2] # stride must be either 1 or 2\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = stride == 1 and inp == oup\n",
    "        \n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(ConvBlock(inp, hidden_dim, 1, INTERNAL_BIT_WIDTH, INTERNAL_BIT_WIDTH))\n",
    "        layers.extend([\n",
    "            ConvBlock(hidden_dim, hidden_dim, 3, INTERNAL_BIT_WIDTH, INTERNAL_BIT_WIDTH, stride=stride, groups=hidden_dim), #depthwise\n",
    "            QuantConv2d(hidden_dim, oup, 1, stride=1, padding=0, bias=False, \n",
    "                        weight_bit_width=INTERNAL_BIT_WIDTH,\n",
    "                        weight_quant=CommonIntWeightPerChannelQuant,\n",
    "                        weight_scaling_per_output_channel=True,\n",
    "                        weight_scaling_impl_type=ScalingImplType.STATS,\n",
    "                        weight_scaling_stats_op='abs_max',\n",
    "                        weight_narrow_range=True,\n",
    "                        weight_scaling_min_val=2e-16\n",
    "                       ), #pointwise, without ReLU6 \n",
    "            nn.BatchNorm2d(oup)\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab4f8c-5023-4acf-93cb-bacb8985aa83",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb5dfe-b44e-4a62-9d15-e76020f6ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes = 10,\n",
    "        width_mult=1.0,\n",
    "        round_average_pool=True \n",
    "    ):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        inverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [],\n",
    "            []\n",
    "        ]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e062e-0804-4eba-85ae-4d791c067fd2",
   "metadata": {},
   "source": [
    "# Model Instantiator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9a292-387c-4df5-9410-24b71832f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet_v2():\n",
    "    # output channels\n",
    "    channels = [[32], [16], [24, 24], [32, 32, 32], [64, 64, 64, 64, 96, 96, 96], [160, 160, 160], [320]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0cd26-db3e-402c-bff7-3c738f2a9cb4",
   "metadata": {},
   "source": [
    "# Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b7c22-1a45-4bc3-afbc-3d50d51fd311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
