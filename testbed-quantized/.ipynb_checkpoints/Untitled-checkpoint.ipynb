{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702bb7-f4e6-4b8d-9ec0-8c520ada8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU\n",
    "from brevitas.quant import IntBias\n",
    "\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.quant import Int8ActPerTensorFloat\n",
    "from brevitas.quant import Int8WeightPerTensorFloat\n",
    "from brevitas.quant import Uint8ActPerTensorFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a243ea-1048-4a78-b2c1-56b88e6bcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common quantization settings\n",
    "class CommonIntWeightPerTensorQuant(Int8WeightPerTensorFloat):\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "\n",
    "class CommonIntWeightPerChannelQuant(CommonIntWeightPerTensorQuant):\n",
    "    scaling_per_output_channel = True\n",
    "\n",
    "class CommonIntActQuant(Int8ActPerTensorFloat):\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP\n",
    "\n",
    "class CommonUintActQuant(Uint8ActPerTensorFloat):\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd93bf-b023-485f-98da-8dac202a3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedCustomMNIST(nn.Module):\n",
    "    def __init__(\n",
    "        super(QuantizedCustomMNIST, self).__init__()\n",
    "        # first layer (higher precision) 8 bit\n",
    "        self.conv1 = QuantConv2d(1, 32, kernel_size=3, stride=1, padding=1, weight_bit_width=8, bias=False, weight_quant=CommonIntWeightPerChannelQuant)\n",
    "        self.bn1  = nn.BatchNorm2d(32)\n",
    "        self.relu1 = QuantReLU(bit_width=8, act_quant=CommonUintActQuant)\n",
    "\n",
    "        # second layer (quantized) 4 bit\n",
    "        self.conv2 = QuantConv2d(32, 64, kernel_size=3, stride=1, padding=1, weight_bit_width=4, bias=False, )\n",
    "\n",
    "    ):\n",
    "    def forward(\n",
    "        \n",
    "    ):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
