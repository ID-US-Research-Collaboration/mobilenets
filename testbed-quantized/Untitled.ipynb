{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fb702bb7-f4e6-4b8d-9ec0-8c520ada8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU, QuantIdentity\n",
    "from brevitas.quant import IntBias\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.quant import Int8ActPerTensorFloat, Uint8ActPerTensorFloat, Int32Bias\n",
    "from brevitas.quant import Int8WeightPerTensorFloat, Int8WeightPerChannelFloat\n",
    "from brevitas.quant.scaled_int import Int32Bias\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "54ed18ff-2c3e-408b-a64f-8a408cfe9774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.3\n"
     ]
    }
   ],
   "source": [
    "import brevitas\n",
    "print(brevitas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e9b2d28a-e1e3-48a7-8f06-50c36c1a7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_LAYER_BIT_WIDTH = 8\n",
    "MIDDLE_LAYER_BIT_WIDTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "24a243ea-1048-4a78-b2c1-56b88e6bcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For weights and activations\n",
    "class CommonIntWeightPerTensorQuant(Int8WeightPerTensorFloat):\n",
    "    scaling_min_val = 2e-16\n",
    "\n",
    "class CommonIntWeightPerChannelQuant(Int8WeightPerChannelFloat):\n",
    "    scaling_per_output_channel = True\n",
    "\n",
    "class CommonIntActQuant(Int8ActPerTensorFloat):\n",
    "    scaling_min_val = 2e-16\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP\n",
    "\n",
    "class CommonUintActQuant(Uint8ActPerTensorFloat):\n",
    "    scaling_min_val = 2e-16\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP\n",
    "\n",
    "class CommonUint4ActQuant(CommonUintActQuant):\n",
    "    bit_width = MIDDLE_LAYER_BIT_WIDTH\n",
    "\n",
    "class CommonInt4ActQuant(CommonIntActQuant):\n",
    "    bit_width = MIDDLE_LAYER_BIT_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c9bd93bf-b023-485f-98da-8dac202a3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedCustomMNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedCustomMNISTNet, self).__init__()\n",
    "        \n",
    "        # First layer (8-bit)\n",
    "        self.conv1 = QuantConv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_bit_width=FIRST_LAYER_BIT_WIDTH,\n",
    "            bias=True,\n",
    "            bias_quant=None,\n",
    "            weight_quant=CommonIntWeightPerChannelQuant,\n",
    "            input_quant=None,\n",
    "            output_quant=CommonUintActQuant,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = QuantReLU(\n",
    "            act_quant=CommonUintActQuant,\n",
    "            bit_width=FIRST_LAYER_BIT_WIDTH,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        \n",
    "        # Middle layers (4-bit)\n",
    "        self.conv2 = QuantConv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_bit_width=MIDDLE_LAYER_BIT_WIDTH,\n",
    "            bias=True,\n",
    "            bias_quant=Int32Bias,\n",
    "            weight_quant=CommonIntWeightPerChannelQuant,\n",
    "            input_quant=CommonUint4ActQuant,\n",
    "            output_quant=CommonUint4ActQuant,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = QuantReLU(\n",
    "            act_quant=CommonInt4ActQuant,\n",
    "            bit_width=MIDDLE_LAYER_BIT_WIDTH,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        \n",
    "        self.conv3 = QuantConv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_bit_width=MIDDLE_LAYER_BIT_WIDTH,\n",
    "            bias=True,\n",
    "            bias_quant=Int32Bias,\n",
    "            weight_quant=CommonIntWeightPerChannelQuant,\n",
    "            input_quant=CommonUint4ActQuant,\n",
    "            output_quant=CommonUint4ActQuant,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = QuantReLU(\n",
    "            act_quant=CommonInt4ActQuant,\n",
    "            bit_width=MIDDLE_LAYER_BIT_WIDTH,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers (4-bit)\n",
    "        self.fc1 = QuantLinear(\n",
    "            3136, 128,\n",
    "            bias=True,\n",
    "            weight_bit_width=MIDDLE_LAYER_BIT_WIDTH,\n",
    "            bias_quant=Int32Bias,\n",
    "            weight_quant=CommonIntWeightPerTensorQuant,\n",
    "            input_quant=CommonUint4ActQuant,\n",
    "            output_quant=CommonUint4ActQuant,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        self.relu4 = QuantReLU(\n",
    "            act_quant=CommonInt4ActQuant,\n",
    "            bit_width=MIDDLE_LAYER_BIT_WIDTH,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        \n",
    "        # Last layer (8-bit)\n",
    "        self.fc2 = QuantLinear(\n",
    "            128, 10,\n",
    "            bias=True,\n",
    "            weight_bit_width=FIRST_LAYER_BIT_WIDTH,\n",
    "            bias_quant=IntBias,\n",
    "            weight_quant=CommonIntWeightPerTensorQuant,\n",
    "            input_quant=CommonUintActQuant,\n",
    "            output_quant=CommonUintActQuant,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "42ee7a66-f54f-416d-856b-57598e330a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fcd00dc6-6b0c-42ef-90fd-862bbc097650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "404b691b-5d10-43b2-872d-db815b735eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({accuracy:.2f}%)\\n')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e1804a2b-b411-4f6e-8476-8f4866a84be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_onnx(model, device, filename=\"mnist_cnn_quantized.onnx\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Checking module devices and bit widths:\")\n",
    "    for name, module in model.named_modules():\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"{name} weight is on device: {module.weight.device}\")\n",
    "        if hasattr(module, 'bias') and module.bias is not None:\n",
    "            print(f\"{name} bias is on device: {module.bias.device}\")\n",
    "        if hasattr(module, 'quant_input'):\n",
    "            print(f\"{name} quant_input is on device: {module.quant_input.quant_proxy.device}\")\n",
    "        if hasattr(module, 'weight_quant'):\n",
    "            print(f\"{name} weight_quant is on device: {module.weight_quant.tensor_quant.device}\")\n",
    "        \n",
    "        if hasattr(module, 'bit_width'):\n",
    "            try:\n",
    "                bit_width = module.bit_width()\n",
    "                print(f\"{name} bit_width: {bit_width}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting bit_width for {name}: {str(e)}\")\n",
    "        \n",
    "        if hasattr(module, 'tracked_parameter_list'):\n",
    "            print(f\"{name} tracked parameters: {len(module.tracked_parameter_list)}\")\n",
    "\n",
    "    dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "\n",
    "    try:\n",
    "        export_onnx_qcdq(model, dummy_input, filename, \n",
    "                         input_names=['input'], output_names=['output'],\n",
    "                         opset_version=13)\n",
    "        print(f\"Model saved in QCDQ ONNX format as {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during ONNX export: {str(e)}\")\n",
    "        print(\"Attempting to export without quantization...\")\n",
    "        try:\n",
    "            torch.onnx.export(model, dummy_input, filename, \n",
    "                              input_names=['input'], output_names=['output'],\n",
    "                              opset_version=13)\n",
    "            print(f\"Model saved in standard ONNX format as {filename}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Error during standard ONNX export: {str(e2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e65a2623-b88f-4486-ba25-a818634c0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA is not available. Running on CPU.\")\n",
    "    else:\n",
    "        print(f\"Running on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    model = QuantizedCustomMNISTNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    \n",
    "    train_loader, test_loader = load_data()\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(1, 11):\n",
    "        train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "        accuracy = test(model, device, test_loader, criterion)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'best_quantized_model.pth')\n",
    "    \n",
    "    print(f\"Best test accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "    # Load the best model and save in ONNX format\n",
    "    model = QuantizedCustomMNISTNet().to(device)\n",
    "    model.load_state_dict(torch.load('best_quantized_model.pth', map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # save_onnx(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "37f1010f-538b-4873-95e7-70201071e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "QuantizedCustomMNISTNet(\n",
      "  (conv1): QuantConv2d(\n",
      "    1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverOutputChannelView(\n",
      "                (permute_impl): Identity()\n",
      "              )\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): QuantConv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverOutputChannelView(\n",
      "                (permute_impl): Identity()\n",
      "              )\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3): QuantConv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverOutputChannelView(\n",
      "                (permute_impl): Identity()\n",
      "              )\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): QuantLinear(\n",
      "    in_features=3136, out_features=128, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu4): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc2): QuantLinear(\n",
      "    in_features=128, out_features=10, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): LogFloatRestrictValue(\n",
      "                (power_of_two): PowerOfTwo()\n",
      "              )\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): InplaceLogTwo()\n",
      "            (restrict_preprocess): LogTwo()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuantWithInputBitWidth(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): Identity()\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.320839\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.107477\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.324924\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.010624\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.058026\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.070573\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.031406\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.005675\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.028078\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.031864\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.029844\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.004134\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.005753\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.006508\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.048275\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.052787\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.015403\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.093370\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.006704\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.002681\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.114036\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.008518\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001230\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.010936\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.054948\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.004460\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.015483\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.019579\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.002032\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.024813\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.005200\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.009606\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.013899\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.001759\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.012319\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.003629\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.001602\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.018573\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.003819\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.002251\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.003421\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.001043\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.028571\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000412\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.007797\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000562\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000358\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.009081\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000426\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.069562\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9914/10000 (99.14%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.009363\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000434\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.005395\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000422\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.001999\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.001781\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000759\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.022278\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000299\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000180\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9937/10000 (99.37%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002432\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000475\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.001650\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000495\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.002344\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000129\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.017983\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000162\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.001946\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.000045\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000107\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000448\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000211\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.003417\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000328\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000147\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.018882\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000093\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009133\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.064024\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9922/10000 (99.22%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000361\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000045\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000231\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000220\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000979\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.001277\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000369\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000404\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000065\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000479\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9929/10000 (99.29%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000297\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.000964\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.002081\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.001862\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000028\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000040\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001357\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.000117\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000042\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.000208\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9936/10000 (99.36%)\n",
      "\n",
      "Best test accuracy: 99.38%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "69699c49-13e7-4db9-a020-9414ffdf2a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture and Bit Widths:\n",
      "\n",
      "Layer: conv1\n",
      "Type: QuantConv2d\n",
      "Has Bias: Yes\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "Output Quant: ActQuantProxyFromInjector\n",
      "In Features: 1\n",
      "Out Features: 64\n",
      "Kernel Size: (3, 3)\n",
      "Stride: (1, 1)\n",
      "Padding: (1, 1)\n",
      "\n",
      "Layer: relu1\n",
      "Type: QuantReLU\n",
      "Has Bias: No\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "\n",
      "Layer: conv2\n",
      "Type: QuantConv2d\n",
      "Has Bias: Yes\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "Output Quant: ActQuantProxyFromInjector\n",
      "In Features: 64\n",
      "Out Features: 64\n",
      "Kernel Size: (3, 3)\n",
      "Stride: (1, 1)\n",
      "Padding: (1, 1)\n",
      "\n",
      "Layer: relu2\n",
      "Type: QuantReLU\n",
      "Has Bias: No\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "\n",
      "Layer: conv3\n",
      "Type: QuantConv2d\n",
      "Has Bias: Yes\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "Output Quant: ActQuantProxyFromInjector\n",
      "In Features: 64\n",
      "Out Features: 64\n",
      "Kernel Size: (3, 3)\n",
      "Stride: (1, 1)\n",
      "Padding: (1, 1)\n",
      "\n",
      "Layer: relu3\n",
      "Type: QuantReLU\n",
      "Has Bias: No\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "\n",
      "Layer: fc1\n",
      "Type: QuantLinear\n",
      "Has Bias: Yes\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "Output Quant: ActQuantProxyFromInjector\n",
      "In Features: 3136\n",
      "Out Features: 128\n",
      "\n",
      "Layer: relu4\n",
      "Type: QuantReLU\n",
      "Has Bias: No\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "\n",
      "Layer: fc2\n",
      "Type: QuantLinear\n",
      "Has Bias: Yes\n",
      "Input Quant: ActQuantProxyFromInjector\n",
      "Output Quant: ActQuantProxyFromInjector\n",
      "In Features: 128\n",
      "Out Features: 10\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = QuantizedCustomMNISTNet()\n",
    "model.load_state_dict(torch.load('best_quantized_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Function to print model architecture and bit widths\n",
    "def print_model_info(model):\n",
    "    print(\"Model Architecture and Bit Widths:\")\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (QuantConv2d, QuantLinear, QuantReLU, QuantIdentity)):\n",
    "            print(f\"\\nLayer: {name}\")\n",
    "            print(f\"Type: {type(module).__name__}\")\n",
    "            \n",
    "            if hasattr(module, 'weight_bit_width'):\n",
    "                print(f\"Weight Bit Width: {module.weight_bit_width}\")\n",
    "            \n",
    "            if hasattr(module, 'bias') and module.bias is not None:\n",
    "                print(f\"Has Bias: Yes\")\n",
    "            else:\n",
    "                print(f\"Has Bias: No\")\n",
    "            \n",
    "            if hasattr(module, 'input_quant'):\n",
    "                print(f\"Input Quant: {type(module.input_quant).__name__}\")\n",
    "            \n",
    "            if hasattr(module, 'output_quant'):\n",
    "                print(f\"Output Quant: {type(module.output_quant).__name__}\")\n",
    "            \n",
    "            if isinstance(module, (QuantConv2d, QuantLinear)):\n",
    "                print(f\"In Features: {module.in_channels if isinstance(module, QuantConv2d) else module.in_features}\")\n",
    "                print(f\"Out Features: {module.out_channels if isinstance(module, QuantConv2d) else module.out_features}\")\n",
    "            \n",
    "            if isinstance(module, QuantConv2d):\n",
    "                print(f\"Kernel Size: {module.kernel_size}\")\n",
    "                print(f\"Stride: {module.stride}\")\n",
    "                print(f\"Padding: {module.padding}\")\n",
    "\n",
    "# Print model information\n",
    "print_model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f7d68a75-c5db-4a41-83bf-ec2f88493f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during ONNX export: '>' not supported between instances of 'NoneType' and 'float'\n",
      "Attempting to export without quantization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/quant_tensor/__init__.py:68: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  training = torch.tensor(training, dtype=torch.bool)\n",
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/export/common/handler/qcdq.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert bools\n",
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/quant_tensor/__init__.py:66: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  signed = torch.tensor(signed, dtype=torch.bool)\n",
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/quant_tensor/__init__.py:74: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return self.signed_t.item()\n",
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/export/common/handler/base.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if s != 1:\n",
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/export/common/__init__.py:6: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor is not None and len(tensor.shape) == 1 and tensor.shape[0] == 1:\n",
      "/home/muhammadzaky/.local/lib/python3.10/site-packages/brevitas/export/common/handler/base.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if bit_width <= 8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported in standard ONNX format to quantized_mnist_model.onnx\n"
     ]
    }
   ],
   "source": [
    "# Load the state dict and convert to ONNX\n",
    "def convert_state_dict_to_onnx(state_dict_path, onnx_path):\n",
    "    # Create an instance of the model\n",
    "    model = QuantizedCustomMNISTNet()\n",
    "    \n",
    "    # Load the state dict\n",
    "    model.load_state_dict(torch.load(state_dict_path, map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a dummy input tensor\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "    \n",
    "    # Export the model to ONNX\n",
    "    try:\n",
    "        export_onnx_qcdq(model, dummy_input, onnx_path, \n",
    "                         input_names=['input'], output_names=['output'],\n",
    "                         opset_version=13)\n",
    "        print(f\"Model successfully exported to {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during ONNX export: {str(e)}\")\n",
    "        print(\"Attempting to export without quantization...\")\n",
    "        try:\n",
    "            torch.onnx.export(model, dummy_input, onnx_path, \n",
    "                              input_names=['input'], output_names=['output'],\n",
    "                              opset_version=13)\n",
    "            print(f\"Model exported in standard ONNX format to {onnx_path}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Error during standard ONNX export: {str(e2)}\")\n",
    "\n",
    "# Use the function\n",
    "state_dict_path = 'best_quantized_model.pth'\n",
    "onnx_path = 'quantized_mnist_model.onnx'\n",
    "convert_state_dict_to_onnx(state_dict_path, onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bcddfd7d-4e1c-4976-95bc-a880384c2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 3\n",
      "Output probabilities: tensor([[0.0080, 0.0445, 0.0445, 0.5999, 0.0080, 0.2282, 0.0126, 0.0383, 0.0080,\n",
      "         0.0080]])\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_path):\n",
    "    model = QuantizedCustomMNISTNet()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def inference(model, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the model\n",
    "    model_path = 'best_quantized_model.pth'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Create a dummy input (replace this with your actual input data)\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)  # Batch size 1, 1 channel, 28x28 image\n",
    "\n",
    "    # Perform inference\n",
    "    output = inference(model, dummy_input)\n",
    "\n",
    "    # Process the output\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print(f\"Output probabilities: {torch.exp(output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7e2ac93a-d1a7-45ba-8b25-106498b1ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization Inspection:\n",
      "-----------------------\n",
      "\n",
      "Layer: conv1\n",
      "Type: QuantConv2d\n",
      "Weight shape: torch.Size([64, 1, 3, 3])\n",
      "Weight dtype: torch.float32\n",
      "Weight range: [-0.4256, 0.3891]\n",
      "Weight unique values: 576\n",
      "Weight bit width: 8.0\n",
      "Bias shape: torch.Size([64])\n",
      "Bias dtype: torch.float32\n",
      "Bias range: [-0.3680, 0.3238]\n",
      "Bias unique values: 64\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: None\n",
      "Output quantization: ActQuantProxyFromInjector\n",
      "Output bit width: 8.0\n",
      "\n",
      "Layer: relu1\n",
      "Type: QuantReLU\n",
      "Activation quantization: ActQuantProxyFromInjector\n",
      "Activation bit width: 8.0\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: None\n",
      "\n",
      "Layer: conv2\n",
      "Type: QuantConv2d\n",
      "Weight shape: torch.Size([64, 64, 3, 3])\n",
      "Weight dtype: torch.float32\n",
      "Weight range: [-0.1213, 0.1581]\n",
      "Weight unique values: 36852\n",
      "Weight bit width: 4.0\n",
      "Bias shape: torch.Size([64])\n",
      "Bias dtype: torch.float32\n",
      "Bias range: [-0.0495, 0.0386]\n",
      "Bias unique values: 64\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: 4.0\n",
      "Output quantization: ActQuantProxyFromInjector\n",
      "Output bit width: 4.0\n",
      "\n",
      "Layer: relu2\n",
      "Type: QuantReLU\n",
      "Activation quantization: ActQuantProxyFromInjector\n",
      "Activation bit width: 4.0\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: None\n",
      "\n",
      "Layer: conv3\n",
      "Type: QuantConv2d\n",
      "Weight shape: torch.Size([64, 64, 3, 3])\n",
      "Weight dtype: torch.float32\n",
      "Weight range: [-0.2049, 0.1549]\n",
      "Weight unique values: 36848\n",
      "Weight bit width: 4.0\n",
      "Bias shape: torch.Size([64])\n",
      "Bias dtype: torch.float32\n",
      "Bias range: [-0.0445, 0.0404]\n",
      "Bias unique values: 64\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: 4.0\n",
      "Output quantization: ActQuantProxyFromInjector\n",
      "Output bit width: 4.0\n",
      "\n",
      "Layer: relu3\n",
      "Type: QuantReLU\n",
      "Activation quantization: ActQuantProxyFromInjector\n",
      "Activation bit width: 4.0\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: None\n",
      "\n",
      "Layer: fc1\n",
      "Type: QuantLinear\n",
      "Weight shape: torch.Size([128, 3136])\n",
      "Weight dtype: torch.float32\n",
      "Weight range: [-0.0759, 0.0768]\n",
      "Weight unique values: 400193\n",
      "Weight bit width: 4.0\n",
      "Bias shape: torch.Size([128])\n",
      "Bias dtype: torch.float32\n",
      "Bias range: [-0.0208, 0.0260]\n",
      "Bias unique values: 128\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: 4.0\n",
      "Output quantization: ActQuantProxyFromInjector\n",
      "Output bit width: 4.0\n",
      "\n",
      "Layer: relu4\n",
      "Type: QuantReLU\n",
      "Activation quantization: ActQuantProxyFromInjector\n",
      "Activation bit width: 4.0\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: None\n",
      "\n",
      "Layer: fc2\n",
      "Type: QuantLinear\n",
      "Weight shape: torch.Size([10, 128])\n",
      "Weight dtype: torch.float32\n",
      "Weight range: [-0.2584, 0.3509]\n",
      "Weight unique values: 1280\n",
      "Weight bit width: 8.0\n",
      "Bias shape: torch.Size([10])\n",
      "Bias dtype: torch.float32\n",
      "Bias range: [-0.0457, 0.1273]\n",
      "Bias unique values: 10\n",
      "Input quantization: ActQuantProxyFromInjector\n",
      "Input bit width: 8.0\n",
      "Output quantization: ActQuantProxyFromInjector\n",
      "Output bit width: 8.0\n",
      "\n",
      "Overall Model Statistics:\n",
      "-------------------------\n",
      "Total parameters: 477719\n",
      "Quantized parameters: 477706\n",
      "Percentage of quantized parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU, QuantIdentity\n",
    "\n",
    "def inspect_quantization(model):\n",
    "    print(\"Quantization Inspection:\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (QuantConv2d, QuantLinear, QuantReLU, QuantIdentity)):\n",
    "            print(f\"\\nLayer: {name}\")\n",
    "            print(f\"Type: {type(module).__name__}\")\n",
    "            \n",
    "            # Check weight quantization\n",
    "            if hasattr(module, 'weight'):\n",
    "                weight = module.weight\n",
    "                print(f\"Weight shape: {weight.shape}\")\n",
    "                print(f\"Weight dtype: {weight.dtype}\")\n",
    "                print(f\"Weight range: [{weight.min().item():.4f}, {weight.max().item():.4f}]\")\n",
    "                print(f\"Weight unique values: {torch.unique(weight).numel()}\")\n",
    "                \n",
    "                if hasattr(module.weight_quant, 'bit_width'):\n",
    "                    bit_width = module.weight_quant.bit_width\n",
    "                    if callable(bit_width):\n",
    "                        bit_width = bit_width()\n",
    "                    print(f\"Weight bit width: {bit_width}\")\n",
    "                else:\n",
    "                    print(\"Weight bit width not found\")\n",
    "                \n",
    "                if hasattr(module, 'weight_quant') and hasattr(module.weight_quant, 'scaling_impl'):\n",
    "                    scaling_factor = module.weight_quant.scaling_impl.scaling_factor\n",
    "                    if callable(scaling_factor):\n",
    "                        scaling_factor = scaling_factor()\n",
    "                    print(f\"Weight scaling factor: {scaling_factor}\")\n",
    "\n",
    "            # Check bias quantization\n",
    "            if hasattr(module, 'bias') and module.bias is not None:\n",
    "                bias = module.bias\n",
    "                print(f\"Bias shape: {bias.shape}\")\n",
    "                print(f\"Bias dtype: {bias.dtype}\")\n",
    "                print(f\"Bias range: [{bias.min().item():.4f}, {bias.max().item():.4f}]\")\n",
    "                print(f\"Bias unique values: {torch.unique(bias).numel()}\")\n",
    "\n",
    "            # Check activation quantization\n",
    "            if hasattr(module, 'act_quant'):\n",
    "                print(f\"Activation quantization: {type(module.act_quant).__name__}\")\n",
    "                if hasattr(module.act_quant, 'bit_width'):\n",
    "                    bit_width = module.act_quant.bit_width\n",
    "                    if callable(bit_width):\n",
    "                        bit_width = bit_width()\n",
    "                    print(f\"Activation bit width: {bit_width}\")\n",
    "                if hasattr(module.act_quant, 'scaling_impl'):\n",
    "                    scaling_factor = module.act_quant.scaling_impl.scaling_factor\n",
    "                    if callable(scaling_factor):\n",
    "                        scaling_factor = scaling_factor()\n",
    "                    print(f\"Activation scaling factor: {scaling_factor}\")\n",
    "\n",
    "            # Check input quantization\n",
    "            if hasattr(module, 'input_quant'):\n",
    "                print(f\"Input quantization: {type(module.input_quant).__name__}\")\n",
    "                if hasattr(module.input_quant, 'bit_width'):\n",
    "                    bit_width = module.input_quant.bit_width\n",
    "                    if callable(bit_width):\n",
    "                        bit_width = bit_width()\n",
    "                    print(f\"Input bit width: {bit_width}\")\n",
    "\n",
    "            # Check output quantization\n",
    "            if hasattr(module, 'output_quant'):\n",
    "                print(f\"Output quantization: {type(module.output_quant).__name__}\")\n",
    "                if hasattr(module.output_quant, 'bit_width'):\n",
    "                    bit_width = module.output_quant.bit_width\n",
    "                    if callable(bit_width):\n",
    "                        bit_width = bit_width()\n",
    "                    print(f\"Output bit width: {bit_width}\")\n",
    "\n",
    "    print(\"\\nOverall Model Statistics:\")\n",
    "    print(\"-------------------------\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    \n",
    "    quant_params = sum(p.numel() for name, p in model.named_parameters() if 'weight' in name or 'bias' in name)\n",
    "    print(f\"Quantized parameters: {quant_params}\")\n",
    "    \n",
    "    print(f\"Percentage of quantized parameters: {quant_params/total_params*100:.2f}%\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'best_quantized_model.pth'\n",
    "    model = load_model(model_path)\n",
    "    inspect_quantization(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e6a78416-1346-4298-a19a-395e8cc5c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "99.38\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1133    0    0    0    0    0    2    0    0]\n",
      " [   1    1 1024    0    0    0    2    4    0    0]\n",
      " [   0    0    0 1007    0    2    0    0    1    0]\n",
      " [   0    0    0    0  981    0    0    0    0    1]\n",
      " [   1    0    0    5    0  884    1    0    0    1]\n",
      " [   6    1    0    0    1    0  949    0    1    0]\n",
      " [   0    3    2    0    1    0    0 1021    1    0]\n",
      " [   2    0    2    0    0    0    0    0  968    2]\n",
      " [   1    0    0    1    8    3    0    2    1  993]]\n",
      "\n",
      "Precision:\n",
      "0.9938129545880825\n",
      "\n",
      "Recall:\n",
      "0.9938\n",
      "\n",
      "F1-Score:\n",
      "0.9937969300974159\n",
      "\n",
      "ROC AUC Score:\n",
      "0.9999712560098378\n",
      "\n",
      "Top-3 Accuracy:\n",
      "99.95\n",
      "\n",
      "Average Inference Time (s):\n",
      "0.013727355003356933\n",
      "\n",
      "Model Size (parameters):\n",
      "477719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mnist_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    inference_times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            output = model(data)\n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times.append(inference_time)\n",
    "\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "    # Precision, Recall, F1-Score\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # ROC AUC Score (one-vs-all)\n",
    "    roc_auc = roc_auc_score(all_targets, all_probs, multi_class='ovr', average='weighted')\n",
    "\n",
    "    # Top-3 Accuracy\n",
    "    top3_preds = np.argsort(all_probs, axis=1)[:, -3:]\n",
    "    top3_correct = np.any(top3_preds == all_targets.reshape(-1, 1), axis=1).sum()\n",
    "    top3_accuracy = 100 * top3_correct / total\n",
    "\n",
    "    # Inference Time\n",
    "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "\n",
    "    # Model Size\n",
    "    model_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    results = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC AUC Score': roc_auc,\n",
    "        'Top-3 Accuracy': top3_accuracy,\n",
    "        'Average Inference Time (s)': avg_inference_time,\n",
    "        'Model Size (parameters)': model_size\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'best_quantized_model.pth'\n",
    "    batch_size = 64\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    # Load the data\n",
    "    train_loader, test_loader = load_data(batch_size)\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = evaluate_mnist_model(model, test_loader, device)\n",
    "    \n",
    "    # Print results\n",
    "    for metric, value in results.items():\n",
    "        print(f\"{metric}:\")\n",
    "        print(value)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465a1e4-708d-4fdf-a544-c019c9e5659e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
